{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attractive-place",
   "metadata": {},
   "source": [
    "# TAL - Lab05 word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-associate",
   "metadata": {},
   "source": [
    "## Test et évalutation d'un modèle entraîné sur Google News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-priority",
   "metadata": {},
   "source": [
    "Téléchargement du moèdle `word2vec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "manufactured-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adolescent-scheduling",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KeyedVectors' object has no attribute 'wv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d5f8fe42f9f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mw2v_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word2vec-google-news-300\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw2v_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyedVectors' object has no attribute 'wv'"
     ]
    }
   ],
   "source": [
    "w2v_model = api.load(\"word2vec-google-news-300\")\n",
    "# the following doesn't word Q_Q\n",
    "#w2v_vectors = w2v_model.wv\n",
    "#del w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "least-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = '~/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz'\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(path_to_file, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-protocol",
   "metadata": {},
   "source": [
    "b. Quelle place mémoire occupe le processus du notebook une fois les vecteurs de mots chargés ?  \n",
    "Le processus utilise **~4GB** de mémoire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-gasoline",
   "metadata": {},
   "source": [
    "c. Quelle est la dimension de l’espace vectoriel dans lequel les mots sont représentés?  \n",
    "La dimension est de **300**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "genetic-developer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vectors.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-prayer",
   "metadata": {},
   "source": [
    "d. Quelle est la taille du vocabulaire du modèle?  \n",
    "La taille du vocabulaire est du **3'000'000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fitting-subscription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is dog in the vocabulary? True\n",
      "is cat in the vocabulary? True\n",
      "is teacher in the vocabulary? True\n",
      "is engineer in the vocabulary? True\n",
      "is switzerland in the vocabulary? True\n",
      "is t-shirt in the vocabulary? False\n",
      "is xylography in the vocabulary? False\n"
     ]
    }
   ],
   "source": [
    "words = [\"dog\", \"cat\", \"teacher\", \"engineer\", \"switzerland\", \"t-shirt\", \"xylography\"]\n",
    "w2v_vectors.vectors.shape\n",
    "\n",
    "for word in words:\n",
    "    print(\"is {} in the vocabulary? {}\".format(word, w2v_vectors.has_index_for(word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-freeware",
   "metadata": {},
   "source": [
    "e. Quelle est la distance entre les mots rabbit et carrot?  \n",
    "La distance entre `rabit` et `carrot` est **0.636**. Cette distance et calculé grace à la **similarité cosinus**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ambient-fever",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6369356513023376"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vectors.distance(\"rabbit\", \"carrot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-barrier",
   "metadata": {},
   "source": [
    "f. Considérez 5-10 paires de mots, certains proches sémantiquement, d’autres non.  Pour chaque paire, calculez la distance entre les deux mots.  Veuillez indiquer si les distances obtenues correspondent à vos intuitions sur la proximité des sens des mots.  \n",
    "Correspond a notre intuitions:  \n",
    "* (\"friend\", \"family\") - Oui  \n",
    "* (\"cat\", \"kitten\") - Oui  \n",
    "* (\"sword\", \"ball\") - Oui/Non (on pensait qu'ils seraient plus loin)  \n",
    "* (\"shirt\", \"jeans\") - Oui  \n",
    "* (\"bed\", \"plane\") - Oui  \n",
    "* (\"old\", \"cold\") - Oui  \n",
    "* (\"tea\", \"eejit\") - Oui  \n",
    "* (\"computer\", \"programmer\") - Oui/Non (on pensait qu'ils seraient plus proche)  \n",
    "* (\"nurse\", \"doctor\") - Oui  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "suitable-honolulu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between 'friend' 'family' is 0.5108\n",
      "distance between 'cat' 'kitten' is 0.2535\n",
      "distance between 'sword' 'ball' is 0.7112\n",
      "distance between 'shirt' 'jeans' is 0.4398\n",
      "distance between 'bed' 'plane' is 0.8260\n",
      "distance between 'old' 'cold' is 0.9185\n",
      "distance between 'tea' 'eejit' is 0.9207\n",
      "distance between 'computer' 'programmer' is 0.5749\n",
      "distance between 'nurse' 'doctor' is 0.3680\n"
     ]
    }
   ],
   "source": [
    "word_pairs = [\n",
    "    (\"friend\", \"family\"),\n",
    "    (\"cat\", \"kitten\"),\n",
    "    (\"sword\", \"ball\"),\n",
    "    (\"shirt\", \"jeans\"),\n",
    "    (\"bed\", \"plane\"),\n",
    "    (\"old\", \"cold\"),\n",
    "    (\"tea\", \"eejit\"),\n",
    "    (\"computer\", \"programmer\"),\n",
    "    (\"nurse\", \"doctor\"),\n",
    "]\n",
    "\n",
    "for word_pair in word_pairs:\n",
    "    print(\"distance between '{}' & '{}' is {:.4f}\".format(\n",
    "        word_pair[0], \n",
    "        word_pair[1], \n",
    "        w2v_vectors.distance(word_pair[0], word_pair[1])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-berry",
   "metadata": {},
   "source": [
    "g. Pouvez-vous trouver des mots de sens opposés mais qui sont proches dans l’espace vectoriel?  \n",
    "\n",
    "`buy` et `sell`\n",
    "\n",
    "Comment expliquez vous cela, et est-ce que c’est selon vous une qualité ou un défaut du modèle word2vec?  \n",
    "Se sont certes des mots de sens opposés mais ils ont un fort lien entre eux (C-à-d l'un ne peu pas exister sans l'autre).\n",
    "C'est clairement une qualité car cela montre que le modèle prend aussi en compte les liens cachés entre les mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "finished-fortune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1691538691520691"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vectors.distance(\"buy\", \"sell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-spanking",
   "metadata": {},
   "source": [
    "h. Trouvez un mot (anglais) qui possède plusieurs sens différents, et pour chaque sens trouvez un mot sémantiquement proche. (Par exemple, en français, avocat—procureur et avocat—banane.) Comparez les différentes distances. Quel est le défaut du modèle word2vec que vous observez?\n",
    "\n",
    "C'est que ces pairs de mots on des sens très proche, mais ils sont très eloignés selon le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "great-float",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between 'bow' & 'arrow' is 0.6049\n",
      "distance between 'bow' & 'tie' is 0.7186\n",
      "distance between 'bow' & 'boat' is 0.7089\n"
     ]
    }
   ],
   "source": [
    "# bow - arrow\n",
    "# bow - tie\n",
    "# bow - boat\n",
    "homograph_pairs = [\n",
    "    (\"bow\", \"arrow\"),\n",
    "    (\"bow\", \"tie\"),\n",
    "    (\"bow\", \"boat\")\n",
    "]\n",
    "\n",
    "for homograph_pair in homograph_pairs:\n",
    "    print(\"distance between '{}' & '{}' is {:.4f}\".format(\n",
    "        homograph_pair[0],\n",
    "        homograph_pair[1],\n",
    "        w2v_vectors.distance(homograph_pair[0], homograph_pair[1])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-transparency",
   "metadata": {},
   "source": [
    "i. Calculez le score du modèle word2vec sur les données **WordSimilarity-353** et expliquer en 1-2 phrases comment ce score est calculé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "minus-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "improving-abortion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.6238773466616107, 1.7963237724171284e-39),\n",
       " SpearmanrResult(correlation=0.6589215888009288, pvalue=2.5346056459149263e-45),\n",
       " 0.0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "natural-antigua",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have length at least 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-c47ec204e12c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2v_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_word_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'questions-words.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tal/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mevaluate_word_pairs\u001b[0;34m(self, pairs, delimiter, restrict_vocab, case_insensitive, dummy4unknown)\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_to_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_key_to_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m         \u001b[0mspearman\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspearmanr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_gold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m         \u001b[0mpearson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_gold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdummy4unknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0moov_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moov\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_gold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tal/lib/python3.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mpearsonr\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   3904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3905\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3906\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x and y must have length at least 2.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3908\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have length at least 2."
     ]
    }
   ],
   "source": [
    "similarities = w2v_vectors.evaluate_word_pairs(datapath('questions-words.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-laser",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
